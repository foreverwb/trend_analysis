"""
æ•°æ®è§¦å‘è·¯ç”±
è´Ÿè´£å¤„ç† Finviz/MarketChameleon æ•°æ®å¯¼å…¥åçš„ IBKR/Futu æ•°æ®è·å–è§¦å‘é€»è¾‘
å®ç°æœºæ„åŒ–å¤šçº§é”šå®šæ¡†æ¶çš„æ•°æ®å±‚çº§ç®¡ç†
"""
from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from sqlalchemy.orm import Session
from typing import Optional, List, Dict, Any
from pydantic import BaseModel
from enum import Enum
import asyncio
import uuid
from datetime import datetime, date
import logging
import time

from ..database import get_db
from ..models import (
    FinvizData, MarketChameleonData, ETFHolding,
    SectorETF, IndustryETF, SymbolPool, SymbolETFMapping
)
from ..config_loader import get_current_config

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/api/data-trigger", tags=["æ•°æ®è§¦å‘"])


# ==================== é€Ÿç‡æ§åˆ¶å™¨ ====================

class RateLimiter:
    """
    é€Ÿç‡æ§åˆ¶å™¨
    ç”¨äºæ§åˆ¶ API è°ƒç”¨é¢‘ç‡ï¼Œé¿å…è§¦å‘é™æµ
    """
    def __init__(self, max_requests_per_minute: int = 50, name: str = "default"):
        self.max_requests_per_minute = max_requests_per_minute
        self.name = name
        self._request_times: List[float] = []
        self._lock = asyncio.Lock()
    
    async def acquire(self):
        """
        è·å–è¯·æ±‚è®¸å¯
        å¦‚æœè¶…è¿‡é€Ÿç‡é™åˆ¶ï¼Œä¼šç­‰å¾…ç›´åˆ°å¯ä»¥å‘é€è¯·æ±‚
        """
        async with self._lock:
            now = time.time()
            
            # æ¸…ç†è¶…è¿‡ 60 ç§’çš„è¯·æ±‚è®°å½•
            self._request_times = [t for t in self._request_times if now - t < 60]
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
            if len(self._request_times) >= self.max_requests_per_minute:
                # è®¡ç®—éœ€è¦ç­‰å¾…çš„æ—¶é—´
                oldest = self._request_times[0]
                wait_time = 60 - (now - oldest) + 0.1  # é¢å¤– 0.1 ç§’ç¼“å†²
                
                if wait_time > 0:
                    logger.info(f"[{self.name}] é€Ÿç‡é™åˆ¶: å·²è¾¾ {len(self._request_times)}/{self.max_requests_per_minute} æ¬¡/åˆ†é’Ÿ, "
                               f"ç­‰å¾… {wait_time:.1f} ç§’")
                    await asyncio.sleep(wait_time)
                    
                    # é‡æ–°æ¸…ç†
                    now = time.time()
                    self._request_times = [t for t in self._request_times if now - t < 60]
            
            # è®°å½•æœ¬æ¬¡è¯·æ±‚
            self._request_times.append(now)
            
            logger.debug(f"[{self.name}] é€Ÿç‡: {len(self._request_times)}/{self.max_requests_per_minute} æ¬¡/åˆ†é’Ÿ")
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–é€Ÿç‡ç»Ÿè®¡"""
        now = time.time()
        recent = [t for t in self._request_times if now - t < 60]
        return {
            "name": self.name,
            "current_rate": len(recent),
            "max_rate": self.max_requests_per_minute,
            "utilization": len(recent) / self.max_requests_per_minute * 100
        }


# åˆ›å»ºé€Ÿç‡æ§åˆ¶å™¨å®ä¾‹
_ibkr_rate_limiter = RateLimiter(max_requests_per_minute=45, name="IBKR")  # é¢„ç•™ 5 æ¬¡ç¼“å†²
_futu_rate_limiter = RateLimiter(max_requests_per_minute=55, name="Futu")  # é¢„ç•™ 5 æ¬¡ç¼“å†²


# ==================== æ•°æ®æ¨¡å‹ ====================

class DataSourceStatus(str, Enum):
    COMPLETE = "complete"
    PARTIAL = "partial"
    MISSING = "missing"


class ETFType(str, Enum):
    MARKET = "market"       # Level 0: SPY, QQQ
    SECTOR = "sector"       # Level 1: XLK, XLF, XLE...
    INDUSTRY = "industry"   # Level 2: SOXX, SMH, IGV...


class TopNAnalysisRequest(BaseModel):
    etf_symbol: str
    holdings_count: int = 40


class TopNAnalysisResult(BaseModel):
    top_n: int
    weight_coverage: float
    meets_threshold: bool


class TopNAnalysisResponse(BaseModel):
    etf_symbol: str
    total_holdings: int
    analysis: List[TopNAnalysisResult]
    recommended_top_n: int
    threshold: float = 0.70


class BatchUpdateRequest(BaseModel):
    symbols: List[str]
    sources: List[str] = ["ibkr", "futu"]
    etf_symbol: Optional[str] = None


class BatchUpdateStatus(BaseModel):
    session_id: str
    status: str  # pending, running, completed, cancelled, failed
    total: int
    completed: int
    current_symbol: Optional[str] = None
    current_source: Optional[str] = None
    errors: List[Dict[str, str]] = []
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    rate_stats: Optional[Dict[str, Any]] = None
    # æ–°å¢ï¼šé¢„ä¼°æ—¶é—´ç›¸å…³
    elapsed_seconds: Optional[float] = None  # å·²ç”¨æ—¶é—´ï¼ˆç§’ï¼‰
    avg_time_per_symbol: Optional[float] = None  # æ¯ä¸ªæ ‡çš„å¹³å‡æ—¶é—´ï¼ˆç§’ï¼‰
    eta_seconds: Optional[float] = None  # é¢„ä¼°å‰©ä½™æ—¶é—´ï¼ˆç§’ï¼‰


class PendingSymbol(BaseModel):
    symbol: str
    weight: float
    has_finviz: bool
    has_mc: bool
    has_ibkr: bool
    has_futu: bool


class DataLayerItem(BaseModel):
    symbol: str
    name: str
    etf_type: ETFType
    data_status: Dict[str, str]
    etf_self_status: Dict[str, str] = {}
    holdings_status: Dict[str, str] = {}
    score: Optional[float] = None
    can_calculate: bool = False
    is_anchor: bool = False
    is_attack: bool = False
    holdings_count: int = 0
    top_n: int = 20
    industries: Optional[List[str]] = None


class DataOverviewResponse(BaseModel):
    level_0: List[DataLayerItem]
    level_1: List[DataLayerItem]
    level_2: Dict[str, List[DataLayerItem]]
    active_sector: Optional[str] = None


class QuickUpdateRequest(BaseModel):
    top_n: int = 20
    sources: List[str] = ["ibkr", "futu"]


# ==================== ETF é…ç½® ====================

ETF_CONFIG = {
    # Level 0 - å¸‚åœºçŠ¶æ€é”š
    "SPY": {"name": "SPDR S&P 500", "type": ETFType.MARKET, "default_holdings": 503},
    "QQQ": {"name": "Invesco QQQ", "type": ETFType.MARKET, "default_holdings": 101},
    
    # Level 1 - æ¿å— ETF (11ä¸ªGICSæ¿å—)
    "XLK": {"name": "ç§‘æŠ€æ¿å—", "type": ETFType.SECTOR, "default_holdings": 68, 
            "industries": ["SOXX", "SMH", "IGV", "CLOU", "HACK"]},
    "XLF": {"name": "é‡‘èæ¿å—", "type": ETFType.SECTOR, "default_holdings": 72,
            "industries": ["KBE", "KRE", "IAI"]},
    "XLE": {"name": "èƒ½æºæ¿å—", "type": ETFType.SECTOR, "default_holdings": 23,
            "industries": ["XOP", "OIH", "VDE"]},
    "XLY": {"name": "éå¿…éœ€æ¶ˆè´¹", "type": ETFType.SECTOR, "default_holdings": 53,
            "industries": ["XRT", "IBUY", "PEJ"]},
    "XLI": {"name": "å·¥ä¸šæ¿å—", "type": ETFType.SECTOR, "default_holdings": 78,
            "industries": ["XAR", "ITA", "JETS"]},
    "XLV": {"name": "åŒ»ç–—ä¿å¥", "type": ETFType.SECTOR, "default_holdings": 64,
            "industries": ["XBI", "IBB", "IHI"]},
    "XLC": {"name": "é€šä¿¡æœåŠ¡", "type": ETFType.SECTOR, "default_holdings": 26,
            "industries": ["FCOM", "VOX"]},
    "XLP": {"name": "å¿…éœ€æ¶ˆè´¹", "type": ETFType.SECTOR, "default_holdings": 38,
            "industries": ["PBJ", "VDC"]},
    "XLU": {"name": "å…¬ç”¨äº‹ä¸š", "type": ETFType.SECTOR, "default_holdings": 31,
            "industries": ["VPU", "FUTY"]},
    "XLRE": {"name": "æˆ¿åœ°äº§", "type": ETFType.SECTOR, "default_holdings": 32,
             "industries": ["VNQ", "IYR"]},
    "XLB": {"name": "åŸææ–™", "type": ETFType.SECTOR, "default_holdings": 28,
            "industries": ["GDX", "XME", "LIT"]},
    
    # Level 2 - è¡Œä¸š ETF
    "SOXX": {"name": "åŠå¯¼ä½“è¡Œä¸šé”š", "type": ETFType.INDUSTRY, "default_holdings": 35, 
             "parent": "XLK", "is_anchor": True},
    "SMH": {"name": "åŠå¯¼ä½“è¿›æ”»é”š", "type": ETFType.INDUSTRY, "default_holdings": 26, 
            "parent": "XLK", "is_attack": True},
    "IGV": {"name": "è½¯ä»¶", "type": ETFType.INDUSTRY, "default_holdings": 103, "parent": "XLK"},
    "CLOU": {"name": "äº‘è®¡ç®—", "type": ETFType.INDUSTRY, "default_holdings": 37, "parent": "XLK"},
    "HACK": {"name": "ç½‘ç»œå®‰å…¨", "type": ETFType.INDUSTRY, "default_holdings": 26, "parent": "XLK"},
    "XBI": {"name": "ç”Ÿç‰©æŠ€æœ¯", "type": ETFType.INDUSTRY, "default_holdings": 131, "parent": "XLV"},
    "IBB": {"name": "ç”Ÿç‰©ç§‘æŠ€", "type": ETFType.INDUSTRY, "default_holdings": 271, "parent": "XLV"},
    "IHI": {"name": "åŒ»ç–—è®¾å¤‡", "type": ETFType.INDUSTRY, "default_holdings": 60, "parent": "XLV"},
    "KBE": {"name": "é“¶è¡Œ", "type": ETFType.INDUSTRY, "default_holdings": 95, "parent": "XLF"},
    "KRE": {"name": "åœ°åŒºé“¶è¡Œ", "type": ETFType.INDUSTRY, "default_holdings": 135, "parent": "XLF"},
    "XOP": {"name": "æ²¹æ°”å¼€é‡‡", "type": ETFType.INDUSTRY, "default_holdings": 60, "parent": "XLE"},
    "OIH": {"name": "æ²¹æœ", "type": ETFType.INDUSTRY, "default_holdings": 25, "parent": "XLE"},
    "XRT": {"name": "é›¶å”®", "type": ETFType.INDUSTRY, "default_holdings": 80, "parent": "XLY"},
    "XHB": {"name": "ä½å®…å»ºç­‘", "type": ETFType.INDUSTRY, "default_holdings": 35, "parent": "XLY"},
    "GDX": {"name": "é»„é‡‘çŸ¿ä¸š", "type": ETFType.INDUSTRY, "default_holdings": 50, "parent": "XLB"},
    "XME": {"name": "é‡‘å±çŸ¿ä¸š", "type": ETFType.INDUSTRY, "default_holdings": 30, "parent": "XLB"},
}

# æ‰¹é‡æ›´æ–°ä¼šè¯å­˜å‚¨
_batch_sessions: Dict[str, BatchUpdateStatus] = {}


# ==================== æœåŠ¡è°ƒç”¨å°è£… ====================

async def fetch_ibkr_data(symbol: str, rate_limiter: RateLimiter) -> Dict[str, Any]:
    """
    ä» IBKR è·å–æ•°æ®ï¼ˆå¸¦é€Ÿç‡æ§åˆ¶ï¼‰
    ä»…è·å–å¸‚åœºæ•°æ®ï¼ˆä»·æ ¼ï¼‰ï¼ŒæœŸæƒæ•°æ®ç”± Futu æä¾›
    """
    await rate_limiter.acquire()
    
    try:
        from ..services.ibkr_service import get_ibkr_service
        
        ibkr = get_ibkr_service()
        if not ibkr.enabled:
            return {"success": False, "error": "IBKR æœåŠ¡æœªå¯ç”¨", "symbol": symbol}
        
        # ä»…è·å–å¸‚åœºæ•°æ®
        market_data = await ibkr.get_market_data(symbol)
        
        return {
            "success": market_data is not None and market_data.get('price') is not None,
            "symbol": symbol,
            "source": "ibkr",
            "market_data": market_data,
            "positioning_data": None,  # æœŸæƒæ•°æ®ç”± Futu è·å–
            "term_data": None,
            "timestamp": datetime.now()
        }
        
    except Exception as e:
        logger.debug(f"IBKR {symbol} å¼‚å¸¸: {e}")
        return {"success": False, "error": str(e), "symbol": symbol, "source": "ibkr"}


async def fetch_futu_data(symbol: str, rate_limiter: RateLimiter, underlying_price: float = None) -> Dict[str, Any]:
    """
    ä» Futu è·å–æ•°æ®ï¼ˆå¸¦é€Ÿç‡æ§åˆ¶ï¼‰
    ä¸»è¦è·å–æœŸæƒæ•°æ®ï¼ˆOI, IVï¼‰
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        rate_limiter: é€Ÿç‡æ§åˆ¶å™¨
        underlying_price: æ ‡çš„ä»·æ ¼ï¼ˆä»IBKRè·å–ï¼Œç”¨äºè®¡ç®—ATM strikeï¼‰
    """
    await rate_limiter.acquire()
    
    try:
        from ..services.futu_service import get_futu_service
        
        futu = get_futu_service()
        if not futu.enabled:
            return {"success": False, "error": "Futu æœåŠ¡æœªå¯ç”¨", "symbol": symbol}
        
        # è·å–æœŸæƒæ•°æ®ï¼ˆä¸å†è°ƒç”¨ get_market_snapshotï¼Œå› ä¸º Futu æ²¡æœ‰ç¾è‚¡è¡Œæƒ…æƒé™ï¼‰
        positioning_data = None
        term_data = None
        positioning_error = None
        term_error = None
        
        try:
            positioning_data = await futu.calculate_positioning_score(symbol)
        except Exception as e:
            positioning_error = str(e)
        
        try:
            # ä¼ é€’ underlying_price ç”¨äºè®¡ç®— ATM strike
            term_data = await futu.calculate_term_score(symbol, underlying_price)
        except Exception as e:
            term_error = str(e)
        
        # åˆ¤æ–­æˆåŠŸï¼šè‡³å°‘è·å–åˆ° positioning æˆ– term æ•°æ®ä¹‹ä¸€
        success = positioning_data is not None or term_data is not None
        
        # æ„å»ºé”™è¯¯ä¿¡æ¯
        error_msg = None
        if not success:
            errors = []
            if positioning_error:
                errors.append(f"positioning: {positioning_error}")
            if term_error:
                errors.append(f"term: {term_error}")
            if not errors:
                if underlying_price is None:
                    error_msg = "æ— æ ‡çš„ä»·æ ¼ï¼Œæ— æ³•è®¡ç®—IVæ•°æ®"
                else:
                    error_msg = "æœŸæƒæ•°æ®ä¸å¯ç”¨"
            else:
                error_msg = "; ".join(errors)
        
        return {
            "success": success,
            "symbol": symbol,
            "source": "futu",
            "snapshot_data": None,  # Futu æ²¡æœ‰ç¾è‚¡è¡Œæƒ…æƒé™
            "positioning_data": positioning_data,
            "term_data": term_data,
            "error": error_msg,
            "timestamp": datetime.now()
        }
        
    except Exception as e:
        logger.debug(f"Futu {symbol} å¼‚å¸¸: {e}")
        return {"success": False, "error": str(e), "symbol": symbol, "source": "futu"}


# ==================== è¾…åŠ©å‡½æ•° ====================

def get_etf_data_status(db: Session, symbol: str, today: date = None) -> Dict[str, str]:
    """è·å– ETF è‡ªèº«çš„æ•°æ®å®Œå¤‡çŠ¶æ€"""
    if today is None:
        today = date.today()
    
    status = {}
    
    # æ£€æŸ¥ Finviz æ•°æ®
    finviz = db.query(FinvizData).filter(
        FinvizData.etf_symbol == symbol,
        FinvizData.ticker == symbol,
        FinvizData.data_date == today
    ).first()
    status["finviz"] = DataSourceStatus.COMPLETE if finviz else DataSourceStatus.MISSING
    
    # æ£€æŸ¥ MarketChameleon æ•°æ®
    mc = db.query(MarketChameleonData).filter(
        MarketChameleonData.symbol == symbol,
        MarketChameleonData.data_date == today
    ).first()
    status["mc"] = DataSourceStatus.COMPLETE if mc else DataSourceStatus.MISSING
    
    # IBKR å’Œ Futu æš‚æ—¶æ ‡è®°ä¸ºå¾…è·å–ï¼ˆéœ€è¦é›†æˆå®é™…æœåŠ¡ï¼‰
    status["ibkr"] = DataSourceStatus.MISSING
    status["futu"] = DataSourceStatus.MISSING
    
    return status


def get_holdings_data_status(db: Session, etf_symbol: str, today: date = None) -> Dict[str, str]:
    """è·å– ETF æŒä»“æˆåˆ†è‚¡çš„æ•°æ®å®Œå¤‡çŠ¶æ€"""
    if today is None:
        today = date.today()
    
    # è·å–æŒä»“åˆ—è¡¨
    holdings = db.query(ETFHolding).filter(
        ETFHolding.etf_symbol == etf_symbol,
        ETFHolding.data_date == today
    ).all()
    
    if not holdings:
        return {
            "finviz": DataSourceStatus.MISSING,
            "mc": DataSourceStatus.MISSING,
            "ibkr": DataSourceStatus.MISSING,
            "futu": DataSourceStatus.MISSING
        }
    
    tickers = [h.ticker for h in holdings]
    
    # æ£€æŸ¥å„æ•°æ®æºè¦†ç›–æƒ…å†µ
    finviz_count = db.query(FinvizData).filter(
        FinvizData.etf_symbol == etf_symbol,
        FinvizData.ticker.in_(tickers),
        FinvizData.data_date == today
    ).count()
    
    mc_count = db.query(MarketChameleonData).filter(
        MarketChameleonData.etf_symbol == etf_symbol,
        MarketChameleonData.symbol.in_(tickers),
        MarketChameleonData.data_date == today
    ).count()
    
    total = len(tickers)
    threshold = 0.7  # 70% è¦†ç›–è®¤ä¸ºå®Œæ•´
    
    return {
        "finviz": DataSourceStatus.COMPLETE if finviz_count >= total * threshold else (
            DataSourceStatus.PARTIAL if finviz_count > 0 else DataSourceStatus.MISSING
        ),
        "mc": DataSourceStatus.COMPLETE if mc_count >= total * threshold else (
            DataSourceStatus.PARTIAL if mc_count > 0 else DataSourceStatus.MISSING
        ),
        "ibkr": DataSourceStatus.MISSING,
        "futu": DataSourceStatus.MISSING
    }


def calculate_weight_coverage(holdings: List, top_n: int) -> float:
    """è®¡ç®— Top N çš„æƒé‡è¦†ç›–ç‡"""
    sorted_holdings = sorted(holdings, key=lambda x: x.weight, reverse=True)
    return sum(h.weight for h in sorted_holdings[:top_n]) / 100.0


async def _sync_to_momentum_stocks(db: Session, symbols: List[str]) -> int:
    """
    åŒæ­¥æŒ‡å®šæ ‡çš„åˆ° MomentumStock è¡¨
    
    Args:
        db: æ•°æ®åº“ä¼šè¯
        symbols: è¦åŒæ­¥çš„æ ‡çš„åˆ—è¡¨
    
    Returns:
        åŒæ­¥æˆåŠŸçš„æ•°é‡
    """
    from ..models import SymbolPool, MomentumStock, ETFHolding, MarketChameleonData, FinvizData
    from ..services.calculation import CalculationService
    
    calc_service = CalculationService(db)
    synced = 0
    
    for ticker in symbols:
        try:
            # è·å– SymbolPool æ•°æ®
            pool = db.query(SymbolPool).filter(SymbolPool.ticker == ticker).first()
            if not pool or not pool.price:
                continue
            
            # è·å– ETF å…³è”ä¿¡æ¯
            holding = db.query(ETFHolding).filter(ETFHolding.ticker == ticker).first()
            
            # è·å– MarketChameleon æ•°æ®
            mc_data = db.query(MarketChameleonData).filter(
                MarketChameleonData.symbol == ticker
            ).order_by(MarketChameleonData.data_date.desc()).first()
            
            # è·å– Finviz æ•°æ®
            finviz_data = db.query(FinvizData).filter(
                FinvizData.ticker == ticker
            ).order_by(FinvizData.data_date.desc()).first()
            
            # æ„å»ºæŒ‡æ ‡
            ibkr_metrics = {
                "price": pool.price or 0,
                "sma50": pool.sma50 or 0,
                "sma200": pool.sma200 or 0,
                "rsi": pool.rsi or 50,
                "return_20d": 0,
                "return_63d": 0,
                "near_high_dist": 0,
                "breakout_trigger": False,
                "volume_spike": 1.0,
                "ma_alignment": _get_ma_alignment(pool.price, pool.sma50, pool.sma200) if pool.price else "N/A",
                "slope_20d": 0,
                "continuity": 0.5,
                "max_drawdown_20d": 0,
                "atr_percent": finviz_data.atr / pool.price * 100 if finviz_data and finviz_data.atr and pool.price else 3,
                "dist_from_20ma": 0,
                "up_down_vol_ratio": 1.0
            }
            
            if finviz_data and pool.price:
                if finviz_data.sma50 and finviz_data.sma50 > 0:
                    ibkr_metrics["dist_from_20ma"] = ((pool.price - finviz_data.sma50) / finviz_data.sma50) * 100
                if finviz_data.high_52w and finviz_data.high_52w > 0:
                    ibkr_metrics["near_high_dist"] = (pool.price / finviz_data.high_52w) * 100
            
            # ç¡®å®šæ¿å—å’Œè¡Œä¸š
            sector = holding.sector_etf_symbol if holding else ""
            industry = holding.industry_etf_symbol if holding else ""
            
            # æ›´æ–°æˆ–åˆ›å»º MomentumStock
            stock = db.query(MomentumStock).filter(MomentumStock.symbol == ticker).first()
            if not stock:
                stock = MomentumStock(symbol=ticker)
                db.add(stock)
            
            stock.name = ticker
            stock.price = pool.price
            stock.sector = sector or ""
            stock.industry = industry or ""
            
            # è®¡ç®—è¯„åˆ†
            pm_score = calc_service.calculate_price_momentum_score(ibkr_metrics)
            ts_score = calc_service.calculate_trend_structure_score(ibkr_metrics)
            vp_score = calc_service.calculate_volume_price_score(ibkr_metrics)
            qf_score, heat_level = calc_service.calculate_quality_filter_score(ibkr_metrics)
            oo_score, heat, rel_vol, ivr, iv30 = calc_service.calculate_options_overlay_score(mc_data)
            
            stock.price_momentum_score = pm_score
            stock.trend_structure_score = ts_score
            stock.volume_price_score = vp_score
            stock.quality_filter_score = qf_score
            stock.heat_level = heat_level
            stock.options_overlay_score = oo_score
            stock.options_heat = heat
            stock.options_rel_vol = rel_vol
            stock.options_ivr = ivr
            stock.options_iv30 = pool.iv30 if pool.iv30 else iv30
            
            stock.final_score = calc_service.calculate_stock_composite_score(
                pm_score, ts_score, vp_score, oo_score, qf_score
            )
            
            stock.return_20d = f"+{ibkr_metrics.get('return_20d', 0):.1f}%"
            stock.return_63d = f"+{ibkr_metrics.get('return_63d', 0):.1f}%"
            stock.near_high_dist = f"{ibkr_metrics.get('near_high_dist', 0):.0f}%"
            stock.ma_alignment = ibkr_metrics.get("ma_alignment", "N/A")
            
            synced += 1
            
        except Exception as e:
            logger.debug(f"åŒæ­¥ {ticker} å¤±è´¥: {e}")
    
    db.commit()
    return synced


def can_calculate_score(etf_status: Dict[str, str], holdings_status: Dict[str, str]) -> bool:
    """åˆ¤æ–­æ˜¯å¦æ»¡è¶³è¯„åˆ†è®¡ç®—çš„æœ€ä½æ¡ä»¶"""
    # è‡³å°‘éœ€è¦ ETF è‡ªèº«å’ŒæŒä»“çš„ finviz + mc å®Œå¤‡
    etf_ok = (etf_status.get("finviz") == DataSourceStatus.COMPLETE and
              etf_status.get("mc") == DataSourceStatus.COMPLETE)
    holdings_ok = (holdings_status.get("finviz") in [DataSourceStatus.COMPLETE, DataSourceStatus.PARTIAL] and
                   holdings_status.get("mc") in [DataSourceStatus.COMPLETE, DataSourceStatus.PARTIAL])
    return etf_ok or holdings_ok


async def batch_update_task(session_id: str, symbols: List[str], sources: List[str]):
    """
    åå°æ‰¹é‡æ›´æ–°ä»»åŠ¡ï¼ˆé›†æˆçœŸå®æœåŠ¡è°ƒç”¨å’Œé€Ÿç‡æ§åˆ¶ï¼‰
    æ—¥å¿—æ ¼å¼ï¼šâœ“ [1/10] MU $98.50
    
    æ•°æ®æµï¼š
    1. IBKR è·å–å¸‚åœºæ•°æ®ï¼ˆä»·æ ¼ï¼‰
    2. Futu è·å–æœŸæƒæ•°æ®ï¼ˆä½¿ç”¨IBKRçš„ä»·æ ¼è®¡ç®—ATM strikeï¼‰
    3. ä¿å­˜æ•°æ®åˆ° SymbolPool è¡¨
    """
    from ..database import SessionLocal
    from ..models import SymbolPool
    
    session = _batch_sessions.get(session_id)
    if not session:
        return
    
    session.status = "running"
    session.started_at = datetime.now()
    
    total = len(symbols)
    sources_str = '+'.join(s.upper() for s in sources)
    logger.info(f"ğŸ“Š æ‰¹é‡æ›´æ–° [{sources_str}] å…± {total} ä¸ªæ ‡çš„")
    
    # åˆ›å»ºæ•°æ®åº“ä¼šè¯
    db = SessionLocal()
    
    try:
        for i, symbol in enumerate(symbols):
            if session.status == "cancelled":
                logger.info(f"ğŸ“Š ä»»åŠ¡å·²å–æ¶ˆ [{i}/{total}]")
                break
            
            session.current_symbol = symbol
            symbol_success = True
            underlying_price = None
            market_data = None
            positioning_data = None
            term_data = None
            
            for source in sources:
                if session.status == "cancelled":
                    break
                
                session.current_source = source
                
                try:
                    if source == "ibkr":
                        result = await fetch_ibkr_data(symbol, _ibkr_rate_limiter)
                        session.rate_stats = {
                            "ibkr": _ibkr_rate_limiter.get_stats(),
                            "futu": _futu_rate_limiter.get_stats()
                        }
                        if result.get("success") and result.get("market_data"):
                            market_data = result["market_data"]
                            underlying_price = market_data.get("price")
                            if underlying_price is None:
                                logger.debug(f"{symbol} - IBKR è¿”å›æ•°æ®ä½†ä»·æ ¼ä¸ºç©º")
                        else:
                            logger.debug(f"{symbol} - IBKR è·å–å¤±è´¥: {result.get('error', 'æ— æ•°æ®')}")
                            
                    elif source == "futu":
                        result = await fetch_futu_data(symbol, _futu_rate_limiter, underlying_price)
                        session.rate_stats = {
                            "ibkr": _ibkr_rate_limiter.get_stats(),
                            "futu": _futu_rate_limiter.get_stats()
                        }
                        if result.get("success"):
                            positioning_data = result.get("positioning_data")
                            term_data = result.get("term_data")
                    else:
                        result = {"success": False, "error": f"æœªçŸ¥æ•°æ®æº: {source}"}
                    
                    if not result.get("success"):
                        session.errors.append({
                            "symbol": symbol, 
                            "source": source, 
                            "error": result.get("error", "æœªçŸ¥é”™è¯¯")
                        })
                        symbol_success = False
                        
                except Exception as e:
                    session.errors.append({
                        "symbol": symbol, 
                        "source": source, 
                        "error": str(e)
                    })
                    symbol_success = False
            
            # ä¿å­˜æ•°æ®åˆ° SymbolPoolï¼ˆåªè¦æœ‰ä»»ä½•æ•°æ®å°±ä¿å­˜ï¼Œä¸è¦æ±‚å…¨éƒ¨æˆåŠŸï¼‰
            # ä¿®å¤ï¼šå³ä½¿ Futu å¤±è´¥ï¼ŒIBKR æ•°æ®ä¹Ÿåº”è¯¥ä¿å­˜
            has_any_data = market_data or positioning_data or term_data
            if has_any_data:
                try:
                    pool_record = db.query(SymbolPool).filter(SymbolPool.ticker == symbol).first()
                    if not pool_record:
                        pool_record = SymbolPool(ticker=symbol)
                        db.add(pool_record)
                    
                    # æ›´æ–°å¸‚åœºæ•°æ®ï¼ˆIBKRï¼‰
                    if market_data:
                        pool_record.price = market_data.get("price")
                        pool_record.sma50 = market_data.get("sma50")
                        pool_record.sma200 = market_data.get("sma200")
                        pool_record.rsi = market_data.get("rsi")
                        pool_record.ibkr_status = "ready"
                        pool_record.ibkr_last_update = datetime.now()
                    
                    # æ›´æ–°æœŸæƒæ•°æ®ï¼ˆFutuï¼‰
                    if positioning_data:
                        pool_record.positioning_score = positioning_data.get("positioning_score")
                        pool_record.total_oi = positioning_data.get("total_oi")
                        pool_record.delta_oi_1d = positioning_data.get("delta_oi_1d")
                        pool_record.futu_status = "ready"
                        pool_record.futu_last_update = datetime.now()
                    
                    if term_data:
                        pool_record.term_score = term_data.get("slope")
                        pool_record.iv7 = term_data.get("iv7")
                        pool_record.iv30 = term_data.get("iv30")
                        pool_record.iv60 = term_data.get("iv60")
                        pool_record.iv90 = term_data.get("iv90")
                        pool_record.iv_slope = term_data.get("slope")
                        # å¦‚æœ positioning_data æ²¡æœ‰ total_oiï¼Œä» term_data è·å–
                        if not pool_record.total_oi and term_data.get("total_oi"):
                            pool_record.total_oi = term_data.get("total_oi")
                    
                    db.commit()
                except Exception as e:
                    db.rollback()
                    logger.debug(f"ä¿å­˜ {symbol} æ•°æ®å¤±è´¥: {e}")
            
            session.completed = i + 1
            
            # å¢å¼ºçš„é˜Ÿåˆ—å¼æ—¥å¿—ï¼ˆå‚è€ƒ volatility_analysis é£æ ¼ï¼‰
            log_parts = [f"[{session.completed}/{total}]", symbol]
            
            # ä»·æ ¼ä¿¡æ¯
            if underlying_price:
                log_parts.append(f"${underlying_price:.2f}")
            
            if symbol_success:
                # IV æœŸé™ç»“æ„ä¿¡æ¯
                iv_parts = []
                if term_data:
                    iv30 = term_data.get("iv30")
                    iv60 = term_data.get("iv60")
                    iv90 = term_data.get("iv90")
                    if iv30 is not None:
                        # IV å¯èƒ½æ˜¯å°æ•°å½¢å¼(0.35)æˆ–ç™¾åˆ†æ¯”å½¢å¼(35.0)ï¼Œç»Ÿä¸€æ˜¾ç¤ºä¸ºç™¾åˆ†æ¯”
                        iv30_pct = iv30 * 100 if iv30 < 5 else iv30
                        iv_parts.append(f"IV30={iv30_pct:.1f}%")
                    if iv60 is not None:
                        iv60_pct = iv60 * 100 if iv60 < 5 else iv60
                        iv_parts.append(f"IV60={iv60_pct:.1f}%")
                    if iv90 is not None:
                        iv90_pct = iv90 * 100 if iv90 < 5 else iv90
                        iv_parts.append(f"IV90={iv90_pct:.1f}%")
                
                if iv_parts:
                    log_parts.append("|")
                    log_parts.extend(iv_parts)
                
                # OI ä¿¡æ¯
                if positioning_data:
                    total_oi = positioning_data.get("total_oi")
                    delta_oi = positioning_data.get("delta_oi_1d")
                    if total_oi:
                        oi_str = f"OI={total_oi:,}"
                        if delta_oi is not None:
                            sign = "+" if delta_oi >= 0 else ""
                            oi_str += f" (Î”{sign}{delta_oi:,})"
                        log_parts.append(f"| {oi_str}")
                
                # Positioning Score ä¿¡æ¯
                if positioning_data:
                    ps = positioning_data.get("positioning_score")
                    if ps is not None:
                        log_parts.append(f"| PS={ps:.2f}")
                
                logger.info(f"âœ“ {' '.join(log_parts)}")
            else:
                # å¤±è´¥æ—¶æ˜¾ç¤ºå…·ä½“åŸå› 
                last_error = session.errors[-1] if session.errors else {}
                error_source = last_error.get("source", "").upper()
                error_msg = last_error.get("error", "æœªçŸ¥é”™è¯¯")
                
                # ç®€åŒ–é”™è¯¯ä¿¡æ¯
                if "implied_volatility" in error_msg.lower() or "iv" in error_msg.lower():
                    error_hint = "IVæ•°æ®ä¸å¯ç”¨"
                elif "timeout" in error_msg.lower() or "è¶…æ—¶" in error_msg:
                    error_hint = "è¿æ¥è¶…æ—¶"
                elif "connect" in error_msg.lower() or "è¿æ¥" in error_msg:
                    error_hint = "è¿æ¥å¤±è´¥"
                elif "æœŸæƒ" in error_msg or "option" in error_msg.lower():
                    error_hint = "æ— æœŸæƒæ•°æ®"
                elif "æ ‡çš„ä»·æ ¼" in error_msg or "underlying" in error_msg.lower():
                    error_hint = "æ— æ³•è·å–æ ‡çš„ä»·æ ¼"
                elif "price" in error_msg.lower() or "ä»·æ ¼" in error_msg:
                    error_hint = "ä»·æ ¼æ•°æ®ä¸å¯ç”¨"
                elif error_msg == "æœªçŸ¥é”™è¯¯":
                    # å°è¯•æ ¹æ®æ•°æ®æºç»™å‡ºæ›´æœ‰æ„ä¹‰çš„æç¤º
                    if error_source == "FUTU":
                        error_hint = "FutuæœŸæƒæ•°æ®ä¸å¯ç”¨"
                    elif error_source == "IBKR":
                        error_hint = "IBKRå¸‚åœºæ•°æ®ä¸å¯ç”¨"
                    else:
                        error_hint = "æ•°æ®è·å–å¤±è´¥"
                else:
                    error_hint = error_msg[:30] if len(error_msg) > 30 else error_msg
                
                if underlying_price:
                    logger.warning(f"âš  {' '.join(log_parts)} | {error_source}: {error_hint}")
                else:
                    logger.warning(f"âœ— {' '.join(log_parts)} | {error_hint}")
        
        if session.status != "cancelled":
            session.status = "completed"
        
        session.completed_at = datetime.now()
        session.current_symbol = None
        session.current_source = None
        
        duration = (session.completed_at - session.started_at).total_seconds()
        error_count = len(session.errors)
        avg_time = duration / total if total > 0 else 0
        
        # å¢å¼ºçš„æ±‡æ€»æ—¥å¿—
        if error_count > 0:
            logger.info(f"ğŸ“Š å®Œæˆ {session.completed}/{total} (å¤±è´¥: {error_count}) è€—æ—¶ {duration:.1f}s | å¹³å‡ {avg_time:.1f}s/æ ‡çš„")
        else:
            logger.info(f"ğŸ“Š å®Œæˆ {session.completed}/{total} è€—æ—¶ {duration:.1f}s | å¹³å‡ {avg_time:.1f}s/æ ‡çš„")
        
        # è‡ªåŠ¨åŒæ­¥åˆ° MomentumStock è¡¨ï¼ˆç¡®ä¿åŠ¨èƒ½è‚¡æ± æœ‰æ•°æ®ï¼‰
        try:
            synced_count = await _sync_to_momentum_stocks(db, symbols)
            if synced_count > 0:
                logger.info(f"ğŸ“Š å·²åŒæ­¥ {synced_count} æ¡æ•°æ®åˆ°åŠ¨èƒ½è‚¡æ± ")
        except Exception as sync_err:
            logger.warning(f"åŒæ­¥åˆ°åŠ¨èƒ½è‚¡æ± å¤±è´¥: {sync_err}")
    
    finally:
        db.close()


# ==================== API ç«¯ç‚¹ ====================

@router.get("/overview", response_model=DataOverviewResponse)
async def get_data_overview(db: Session = Depends(get_db)):
    """
    è·å–æ•°æ®å±‚çº§æ¦‚è§ˆ
    è¿”å› Level 0/1/2 å„å±‚çº§çš„ ETF æ•°æ®çŠ¶æ€
    
    ä¼˜åŒ–ï¼šåªæœ‰é…ç½®/ä¸Šä¼ äº† holdings çš„ ETF æ‰ä¼šæ˜¾ç¤ºåœ¨åˆ—è¡¨ä¸­
    """
    today = date.today()
    level_0 = []
    level_1 = []
    level_2 = {}
    
    # ä»æ•°æ®åº“è·å–å®é™…çš„ ETF åˆ—è¡¨
    sector_etfs = db.query(SectorETF).all()
    industry_etfs = db.query(IndustryETF).all()
    
    # æ„å»ºå·²å­˜åœ¨çš„ ETF é›†åˆ
    db_sectors = {e.symbol for e in sector_etfs}
    db_industries = {e.symbol for e in industry_etfs}
    
    # è·å–æ‰€æœ‰æœ‰æŒä»“æ•°æ®çš„ ETF ç¬¦å·ï¼ˆä¸é™åˆ¶æ—¥æœŸï¼‰
    etfs_with_holdings = set(
        row[0] for row in db.query(ETFHolding.etf_symbol).distinct().all()
    )
    
    for symbol, config in ETF_CONFIG.items():
        etf_type = config["type"]
        
        # ã€ä¼˜åŒ–å˜æ›´ã€‘æ¿å— ETF å’Œè¡Œä¸š ETF å¿…é¡»æœ‰ holdings æ‰æ˜¾ç¤º
        # Level 0 (å¸‚åœºé”šå¦‚ SPY, QQQ) å§‹ç»ˆæ˜¾ç¤º
        if etf_type != ETFType.MARKET and symbol not in etfs_with_holdings:
            continue
        
        etf_self_status = get_etf_data_status(db, symbol, today)
        holdings_status = get_holdings_data_status(db, symbol, today)
        
        # åˆå¹¶çŠ¶æ€
        combined_status = {}
        for key in ["finviz", "mc", "ibkr", "futu"]:
            etf_val = etf_self_status.get(key, DataSourceStatus.MISSING)
            hold_val = holdings_status.get(key, DataSourceStatus.MISSING)
            if etf_val == DataSourceStatus.COMPLETE and hold_val == DataSourceStatus.COMPLETE:
                combined_status[key] = DataSourceStatus.COMPLETE
            elif etf_val != DataSourceStatus.MISSING or hold_val != DataSourceStatus.MISSING:
                combined_status[key] = DataSourceStatus.PARTIAL
            else:
                combined_status[key] = DataSourceStatus.MISSING
        
        # è·å–æŒä»“æ•°é‡ï¼ˆä»»æ„æ—¥æœŸï¼‰
        holdings_count = db.query(ETFHolding).filter(
            ETFHolding.etf_symbol == symbol
        ).count()
        
        item = DataLayerItem(
            symbol=symbol,
            name=config["name"],
            etf_type=config["type"],
            data_status=combined_status,
            etf_self_status=etf_self_status,
            holdings_status=holdings_status,
            can_calculate=can_calculate_score(etf_self_status, holdings_status),
            is_anchor=config.get("is_anchor", False),
            is_attack=config.get("is_attack", False),
            holdings_count=holdings_count or config.get("default_holdings", 0),
            top_n=20 if config["type"] == ETFType.SECTOR else 15,
            industries=config.get("industries")
        )
        
        if config["type"] == ETFType.MARKET:
            level_0.append(item)
        elif config["type"] == ETFType.SECTOR:
            level_1.append(item)
        elif config["type"] == ETFType.INDUSTRY:
            parent = config.get("parent", "OTHER")
            if parent not in level_2:
                level_2[parent] = []
            level_2[parent].append(item)
    
    return DataOverviewResponse(
        level_0=level_0,
        level_1=level_1,
        level_2=level_2
    )


@router.post("/analyze-top-n", response_model=TopNAnalysisResponse)
async def analyze_top_n(request: TopNAnalysisRequest, db: Session = Depends(get_db)):
    """
    åˆ†æ ETF æŒä»“çš„ Top N æƒé‡è¦†ç›–ç‡
    è¿”å› Top 10/15/20/25 å„æ¡£ä½çš„è¦†ç›–ç‡å’Œæ¨èå€¼
    """
    etf_symbol = request.etf_symbol.upper()
    today = date.today()
    
    # è·å–æŒä»“æ•°æ®
    holdings = db.query(ETFHolding).filter(
        ETFHolding.etf_symbol == etf_symbol,
        ETFHolding.data_date == today
    ).order_by(ETFHolding.weight.desc()).all()
    
    if not holdings:
        # å°è¯•è·å–ä»»æ„æ—¥æœŸçš„æ•°æ®
        holdings = db.query(ETFHolding).filter(
            ETFHolding.etf_symbol == etf_symbol
        ).order_by(ETFHolding.weight.desc()).all()
    
    if not holdings:
        raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ° {etf_symbol} çš„æŒä»“æ•°æ®")
    
    threshold = 0.70
    top_n_values = [10, 15, 20, 25, 30]
    analysis = []
    recommended = 20
    
    total_weight = sum(h.weight for h in holdings)
    
    for n in top_n_values:
        if n > len(holdings):
            continue
        top_weight = sum(h.weight for h in holdings[:n])
        coverage = top_weight / total_weight if total_weight > 0 else 0
        meets = coverage >= threshold
        analysis.append(TopNAnalysisResult(
            top_n=n,
            weight_coverage=round(coverage, 4),
            meets_threshold=meets
        ))
        if meets and recommended == 20:
            recommended = n
    
    return TopNAnalysisResponse(
        etf_symbol=etf_symbol,
        total_holdings=len(holdings),
        analysis=analysis,
        recommended_top_n=recommended,
        threshold=threshold
    )


@router.get("/pending-symbols/{etf_symbol}", response_model=List[PendingSymbol])
async def get_pending_symbols(
    etf_symbol: str, 
    top_n: int = 20,
    db: Session = Depends(get_db)
):
    """
    è·å– ETF æŒä»“ä¸­å¾…æ›´æ–°å®æ—¶æ•°æ®çš„æ ‡çš„åˆ—è¡¨
    """
    etf_symbol = etf_symbol.upper()
    today = date.today()
    
    holdings = db.query(ETFHolding).filter(
        ETFHolding.etf_symbol == etf_symbol
    ).order_by(ETFHolding.weight.desc()).limit(top_n).all()
    
    if not holdings:
        raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ° {etf_symbol} çš„æŒä»“æ•°æ®")
    
    result = []
    for h in holdings:
        ticker = h.ticker
        
        # æ£€æŸ¥å„æ•°æ®æº
        has_finviz = db.query(FinvizData).filter(
            FinvizData.ticker == ticker,
            FinvizData.data_date == today
        ).first() is not None
        
        has_mc = db.query(MarketChameleonData).filter(
            MarketChameleonData.symbol == ticker,
            MarketChameleonData.data_date == today
        ).first() is not None
        
        result.append(PendingSymbol(
            symbol=ticker,
            weight=h.weight,
            has_finviz=has_finviz,
            has_mc=has_mc,
            has_ibkr=False,  # å¾…å®ç°
            has_futu=False   # å¾…å®ç°
        ))
    
    return result


@router.post("/batch-update", response_model=BatchUpdateStatus)
async def start_batch_update(
    request: BatchUpdateRequest, 
    background_tasks: BackgroundTasks
):
    """
    å¯åŠ¨æ‰¹é‡æ›´æ–°ä»»åŠ¡ï¼ˆå¸¦é€Ÿç‡æ§åˆ¶ï¼‰
    
    é€Ÿç‡é™åˆ¶:
    - IBKR: ~45 æ¬¡/åˆ†é’Ÿ (é¢„ç•™ 5 æ¬¡ç¼“å†²)
    - Futu: ~55 æ¬¡/åˆ†é’Ÿ (é¢„ç•™ 5 æ¬¡ç¼“å†²)
    """
    session_id = str(uuid.uuid4())
    
    status = BatchUpdateStatus(
        session_id=session_id,
        status="pending",
        total=len(request.symbols),
        completed=0,
        errors=[],
        rate_stats={
            "ibkr": _ibkr_rate_limiter.get_stats(),
            "futu": _futu_rate_limiter.get_stats()
        }
    )
    
    _batch_sessions[session_id] = status
    background_tasks.add_task(batch_update_task, session_id, request.symbols, request.sources)
    
    logger.info(f"[æ‰¹é‡æ›´æ–°] åˆ›å»ºä»»åŠ¡ {session_id}: {len(request.symbols)} ä¸ªæ ‡çš„")
    
    return status


@router.get("/batch-update/{session_id}", response_model=BatchUpdateStatus)
async def get_batch_update_status(session_id: str):
    """è·å–æ‰¹é‡æ›´æ–°ä»»åŠ¡çŠ¶æ€ï¼ŒåŒ…å«é¢„ä¼°å®Œæˆæ—¶é—´"""
    status = _batch_sessions.get(session_id)
    if not status:
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°è¯¥æ›´æ–°ä¼šè¯")
    
    # æ›´æ–°é€Ÿç‡ç»Ÿè®¡
    status.rate_stats = {
        "ibkr": _ibkr_rate_limiter.get_stats(),
        "futu": _futu_rate_limiter.get_stats()
    }
    
    # è®¡ç®—é¢„ä¼°æ—¶é—´
    if status.started_at and status.status == "running":
        elapsed = (datetime.now() - status.started_at).total_seconds()
        status.elapsed_seconds = round(elapsed, 1)
        
        if status.completed > 0:
            avg_time = elapsed / status.completed
            status.avg_time_per_symbol = round(avg_time, 2)
            
            remaining = status.total - status.completed
            eta = avg_time * remaining
            status.eta_seconds = round(eta, 1)
    
    return status


@router.post("/batch-update/{session_id}/cancel")
async def cancel_batch_update(session_id: str):
    """å–æ¶ˆæ‰¹é‡æ›´æ–°ä»»åŠ¡"""
    status = _batch_sessions.get(session_id)
    if not status:
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°è¯¥æ›´æ–°ä¼šè¯")
    
    if status.status == "running":
        status.status = "cancelled"
        logger.info(f"[æ‰¹é‡æ›´æ–°] ä»»åŠ¡ {session_id} å·²è¯·æ±‚å–æ¶ˆ")
        return {"message": "å·²å–æ¶ˆæ›´æ–°ä»»åŠ¡", "session_id": session_id}
    return {"message": f"ä»»åŠ¡çŠ¶æ€ä¸º {status.status}ï¼Œæ— æ³•å–æ¶ˆ", "session_id": session_id}


@router.post("/quick-update/{etf_symbol}")
async def quick_update(
    etf_symbol: str, 
    request: QuickUpdateRequest, 
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db)
):
    """
    å¿«æ·æ›´æ–°ï¼šä¸€é”®è·å– ETF æŒä»“ Top N çš„å®æ—¶æ•°æ®
    
    é€Ÿç‡é™åˆ¶:
    - IBKR: ~45 æ¬¡/åˆ†é’Ÿ
    - Futu: ~55 æ¬¡/åˆ†é’Ÿ
    - é¢„è®¡è€—æ—¶: Top 20 çº¦ 1-2 åˆ†é’Ÿï¼ˆå–å†³äºæ•°æ®æºï¼‰
    """
    etf_symbol = etf_symbol.upper()
    
    holdings = db.query(ETFHolding).filter(
        ETFHolding.etf_symbol == etf_symbol
    ).order_by(ETFHolding.weight.desc()).limit(request.top_n).all()
    
    if not holdings:
        raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ° {etf_symbol} çš„æŒä»“æ•°æ®")
    
    symbols_to_update = [h.ticker for h in holdings]
    
    if not symbols_to_update:
        return {"message": "æ‰€æœ‰æ ‡çš„æ•°æ®å·²å®Œå¤‡", "symbols_updated": 0}
    
    # ä¼°ç®—è€—æ—¶
    estimated_time = len(symbols_to_update) * len(request.sources) * 1.5  # æ¯ä¸ªè¯·æ±‚çº¦ 1.5 ç§’
    
    batch_request = BatchUpdateRequest(
        symbols=symbols_to_update,
        sources=request.sources,
        etf_symbol=etf_symbol
    )
    
    result = await start_batch_update(batch_request, background_tasks)
    
    return {
        **result.dict(),
        "estimated_time_seconds": estimated_time,
        "message": f"å·²å¯åŠ¨ Top {request.top_n} æ›´æ–°ä»»åŠ¡ï¼Œé¢„è®¡è€—æ—¶ {estimated_time:.0f} ç§’"
    }


@router.get("/etf-holdings/{etf_symbol}")
async def get_etf_holdings_detail(
    etf_symbol: str, 
    top_n: int = 20,
    db: Session = Depends(get_db)
):
    """è·å– ETF æŒä»“æ˜ç»†åŠæ•°æ®çŠ¶æ€"""
    etf_symbol = etf_symbol.upper()
    today = date.today()
    
    holdings = db.query(ETFHolding).filter(
        ETFHolding.etf_symbol == etf_symbol
    ).order_by(ETFHolding.weight.desc()).limit(top_n).all()
    
    if not holdings:
        raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ° {etf_symbol} çš„æŒä»“æ•°æ®")
    
    result = []
    for h in holdings:
        ticker = h.ticker
        
        finviz = db.query(FinvizData).filter(
            FinvizData.ticker == ticker,
            FinvizData.data_date == today
        ).first()
        
        mc = db.query(MarketChameleonData).filter(
            MarketChameleonData.symbol == ticker,
            MarketChameleonData.data_date == today
        ).first()
        
        data_status = {
            "finviz": DataSourceStatus.COMPLETE if finviz else DataSourceStatus.MISSING,
            "mc": DataSourceStatus.COMPLETE if mc else DataSourceStatus.MISSING,
            "ibkr": DataSourceStatus.MISSING,
            "futu": DataSourceStatus.MISSING
        }
        
        # è®¡ç®— 50MA/200MA çŠ¶æ€
        above_50ma = None
        above_200ma = None
        if finviz and finviz.price and finviz.sma50:
            above_50ma = finviz.price > finviz.sma50
        if finviz and finviz.price and finviz.sma200:
            above_200ma = finviz.price > finviz.sma200
        
        result.append({
            "symbol": ticker,
            "name": "",
            "weight": h.weight,
            "data_status": data_status,
            "above_50ma": above_50ma,
            "above_200ma": above_200ma,
            "price": finviz.price if finviz else None,
            "rsi": finviz.rsi if finviz else None,
            "ivr": mc.ivr if mc else None
        })
    
    # è®¡ç®—å¹¿åº¦ç»Ÿè®¡
    above_50ma_count = sum(1 for r in result if r.get("above_50ma") is True)
    above_200ma_count = sum(1 for r in result if r.get("above_200ma") is True)
    total_with_data = sum(1 for r in result if r.get("above_50ma") is not None)
    
    config = ETF_CONFIG.get(etf_symbol, {"name": etf_symbol, "type": "unknown"})
    
    return {
        "etf_symbol": etf_symbol,
        "config": {
            "name": config.get("name", etf_symbol),
            "type": config.get("type", "unknown"),
            "default_holdings": config.get("default_holdings", 0)
        },
        "holdings": result,
        "total_weight": sum(h.weight for h in holdings),
        "breadth": {
            "above_50ma": f"{above_50ma_count}/{total_with_data}" if total_with_data > 0 else "0/0",
            "above_200ma": f"{above_200ma_count}/{total_with_data}" if total_with_data > 0 else "0/0",
            "above_50ma_pct": round(above_50ma_count / total_with_data * 100, 1) if total_with_data > 0 else 0,
            "above_200ma_pct": round(above_200ma_count / total_with_data * 100, 1) if total_with_data > 0 else 0
        }
    }


@router.get("/rate-stats")
async def get_rate_stats():
    """è·å–å½“å‰é€Ÿç‡æ§åˆ¶ç»Ÿè®¡"""
    return {
        "ibkr": _ibkr_rate_limiter.get_stats(),
        "futu": _futu_rate_limiter.get_stats()
    }


@router.post("/reset-sessions")
async def reset_batch_sessions():
    """é‡ç½®æ‰€æœ‰æ‰¹é‡æ›´æ–°ä¼šè¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
    _batch_sessions.clear()
    return {"message": "å·²é‡ç½®æ‰€æœ‰ä¼šè¯"}


@router.post("/sync-momentum-stocks")
async def sync_momentum_stocks(
    industry_symbol: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """
    ä» SymbolPool åŒæ­¥æ•°æ®åˆ° MomentumStock è¡¨
    
    è¿™ä¸ªæ¥å£è§£å†³"åŠ¨èƒ½è‚¡æ± æ— æ•°æ®"çš„é—®é¢˜ï¼š
    - ä» SymbolPool è·å–æœ‰å®æ—¶æ•°æ®çš„æ ‡çš„
    - åˆ›å»º/æ›´æ–° MomentumStock è®°å½•
    - è®¡ç®—ç»¼åˆè¯„åˆ†
    
    Args:
        industry_symbol: å¯é€‰ï¼ŒæŒ‡å®šè¡Œä¸š ETF ç¬¦å·ï¼ŒåªåŒæ­¥è¯¥è¡Œä¸šçš„æ ‡çš„
    """
    from ..models import SymbolPool, MomentumStock, ETFHolding, MarketChameleonData, FinvizData
    from ..services.calculation import CalculationService
    
    calc_service = CalculationService(db)
    
    # è·å–æœ‰å®æ—¶æ•°æ®çš„ SymbolPool è®°å½•
    pool_query = db.query(SymbolPool).filter(
        SymbolPool.ibkr_status == "ready"  # è‡³å°‘æœ‰ IBKR æ•°æ®
    )
    
    pool_records = pool_query.all()
    
    if not pool_records:
        return {
            "success": True,
            "message": "æ²¡æœ‰å¯åŒæ­¥çš„æ•°æ®",
            "synced": 0,
            "skipped": 0
        }
    
    synced = 0
    skipped = 0
    errors = []
    
    for pool in pool_records:
        try:
            ticker = pool.ticker
            
            # è·å–è¯¥æ ‡çš„çš„ ETF å…³è”ä¿¡æ¯
            holding = db.query(ETFHolding).filter(
                ETFHolding.ticker == ticker
            ).first()
            
            if not holding:
                skipped += 1
                continue
            
            # å¦‚æœæŒ‡å®šäº†è¡Œä¸šï¼ŒåªåŒæ­¥è¯¥è¡Œä¸šçš„æ ‡çš„
            if industry_symbol:
                if holding.industry_etf_symbol != industry_symbol.upper():
                    skipped += 1
                    continue
            
            # è·å– MarketChameleon æ•°æ®
            mc_data = db.query(MarketChameleonData).filter(
                MarketChameleonData.symbol == ticker
            ).order_by(MarketChameleonData.data_date.desc()).first()
            
            # è·å– Finviz æ•°æ®
            finviz_data = db.query(FinvizData).filter(
                FinvizData.ticker == ticker
            ).order_by(FinvizData.data_date.desc()).first()
            
            # æ„å»º IBKR æŒ‡æ ‡ï¼ˆä» SymbolPool æ•°æ®ï¼‰
            ibkr_metrics = {
                "price": pool.price or 0,
                "sma50": pool.sma50 or 0,
                "sma200": pool.sma200 or 0,
                "rsi": pool.rsi or 50,
                # è®¡ç®—è¿”å›ç‡ï¼ˆå¦‚æœæœ‰å†å²æ•°æ®å¯ä»¥æ›´ç²¾ç¡®ï¼‰
                "return_20d": 0,
                "return_20d_ex3": 0,
                "return_63d": 0,
                "near_high_dist": 0,
                "breakout_trigger": False,
                "volume_spike": 1.0,
                "ma_alignment": _get_ma_alignment(pool.price, pool.sma50, pool.sma200) if pool.price else "N/A",
                "slope_20d": 0,
                "continuity": 0.5,
                "max_drawdown_20d": 0,
                "atr_percent": finviz_data.atr / pool.price * 100 if finviz_data and finviz_data.atr and pool.price else 3,
                "dist_from_20ma": 0,
                "up_down_vol_ratio": 1.0
            }
            
            # å¦‚æœæœ‰ Finviz æ•°æ®ï¼Œè¡¥å……æ›´å¤šæŒ‡æ ‡
            if finviz_data and pool.price:
                if finviz_data.sma50 and finviz_data.sma50 > 0:
                    ibkr_metrics["dist_from_20ma"] = ((pool.price - finviz_data.sma50) / finviz_data.sma50) * 100
                if finviz_data.high_52w and finviz_data.high_52w > 0:
                    ibkr_metrics["near_high_dist"] = (pool.price / finviz_data.high_52w) * 100
            
            # ç¡®å®šæ¿å—å’Œè¡Œä¸š
            sector = holding.sector_etf_symbol or ""
            industry = holding.industry_etf_symbol or ""
            
            # æ›´æ–°æˆ–åˆ›å»º MomentumStock
            stock = db.query(MomentumStock).filter(MomentumStock.symbol == ticker).first()
            if not stock:
                stock = MomentumStock(symbol=ticker)
                db.add(stock)
            
            # åŸºæœ¬ä¿¡æ¯
            stock.name = ticker
            stock.price = pool.price
            stock.sector = sector
            stock.industry = industry
            
            # è®¡ç®—è¯„åˆ†
            pm_score = calc_service.calculate_price_momentum_score(ibkr_metrics)
            ts_score = calc_service.calculate_trend_structure_score(ibkr_metrics)
            vp_score = calc_service.calculate_volume_price_score(ibkr_metrics)
            qf_score, heat_level = calc_service.calculate_quality_filter_score(ibkr_metrics)
            oo_score, heat, rel_vol, ivr, iv30 = calc_service.calculate_options_overlay_score(mc_data)
            
            stock.price_momentum_score = pm_score
            stock.trend_structure_score = ts_score
            stock.volume_price_score = vp_score
            stock.quality_filter_score = qf_score
            stock.heat_level = heat_level
            
            stock.options_overlay_score = oo_score
            stock.options_heat = heat
            stock.options_rel_vol = rel_vol
            stock.options_ivr = ivr
            stock.options_iv30 = iv30
            
            # æœŸæƒ IV æ•°æ®ï¼ˆä» SymbolPoolï¼‰
            if pool.iv30:
                stock.options_iv30 = pool.iv30
            
            # è®¡ç®—æœ€ç»ˆè¯„åˆ†
            stock.final_score = calc_service.calculate_stock_composite_score(
                pm_score, ts_score, vp_score, oo_score, qf_score
            )
            
            # å¡«å……å…¶ä»–å­—æ®µ
            stock.return_20d = f"+{ibkr_metrics.get('return_20d', 0):.1f}%"
            stock.return_63d = f"+{ibkr_metrics.get('return_63d', 0):.1f}%"
            stock.near_high_dist = f"{ibkr_metrics.get('near_high_dist', 0):.0f}%"
            stock.ma_alignment = ibkr_metrics.get("ma_alignment", "N/A")
            stock.breakout_trigger = ibkr_metrics.get("breakout_trigger", False)
            stock.volume_spike = ibkr_metrics.get("volume_spike", 1.0)
            
            synced += 1
            
        except Exception as e:
            errors.append({"symbol": pool.ticker, "error": str(e)})
            logger.error(f"åŒæ­¥ {pool.ticker} åˆ° MomentumStock å¤±è´¥: {e}")
    
    db.commit()
    
    message = f"åŒæ­¥å®Œæˆ: {synced} æ¡æˆåŠŸ, {skipped} æ¡è·³è¿‡"
    if errors:
        message += f", {len(errors)} æ¡å¤±è´¥"
    
    return {
        "success": True,
        "message": message,
        "synced": synced,
        "skipped": skipped,
        "errors": errors[:10]  # æœ€å¤šè¿”å›10æ¡é”™è¯¯
    }


def _get_ma_alignment(price: float, sma50: float, sma200: float) -> str:
    """è®¡ç®—å‡çº¿æ’åˆ—çŠ¶æ€"""
    if not price or not sma50:
        return "N/A"
    
    if price > sma50:
        if sma200 and sma50 > sma200:
            return "P>50MA>200MA (å¼ºåŠ¿)"
        return "P>50MA"
    else:
        if sma200 and price < sma200:
            return "P<50MA<200MA (å¼±åŠ¿)"
        return "P<50MA"


@router.get("/ibkr-diagnostic")
async def ibkr_diagnostic():
    """
    IBKR è¿æ¥è¯Šæ–­
    ç”¨äºæ’æŸ¥è¿æ¥é—®é¢˜å’Œæ•°æ®è·å–é—®é¢˜
    """
    from ..services.ibkr_service import get_ibkr_service
    from ..config_loader import get_current_config
    
    config = get_current_config()
    result = {
        "timestamp": datetime.now().isoformat(),
        "config": {
            "host": config.ibkr.host,
            "port": config.ibkr.port,
            "client_id": config.ibkr.client_id,
            "enabled": config.ibkr.enabled,
            "connection_timeout": config.ibkr.connection_timeout,
            "qualify_timeout": config.ibkr.qualify_timeout,
            "request_timeout": config.ibkr.request_timeout,
            "historical_timeout": config.ibkr.historical_timeout,
            "market_data_type": config.ibkr.market_data_type,
            "market_data_type_desc": "å»¶è¿Ÿæ•°æ®(å…è´¹)" if config.ibkr.market_data_type == 3 else "å®æ—¶æ•°æ®(éœ€è®¢é˜…)"
        },
        "connection": {
            "status": "unknown",
            "message": ""
        },
        "test_results": {}
    }
    
    if not config.ibkr.enabled:
        result["connection"]["status"] = "disabled"
        result["connection"]["message"] = "IBKR æœåŠ¡åœ¨é…ç½®ä¸­å·²ç¦ç”¨"
        return result
    
    try:
        ibkr = get_ibkr_service()
        
        connect_start = time.time()
        connected = await ibkr.connect()
        connect_duration = (time.time() - connect_start) * 1000
        
        result["connection"]["status"] = "connected" if connected else "failed"
        result["connection"]["duration_ms"] = round(connect_duration, 0)
        
        if connected:
            result["connection"]["message"] = "è¿æ¥æˆåŠŸ"
            result["connection"]["accounts"] = ibkr.ib.managedAccounts() if ibkr.ib else []
            
            # æµ‹è¯•è·å– SPY å¸‚åœºæ•°æ®
            test_start = time.time()
            try:
                spy_data = await ibkr.get_market_data("SPY")
                test_duration = (time.time() - test_start) * 1000
                
                result["test_results"]["spy_market_data"] = {
                    "status": "success" if spy_data and spy_data.get("price") else "no_data",
                    "price": spy_data.get("price") if spy_data else None,
                    "duration_ms": round(test_duration, 0),
                    "data_source": "delayed" if spy_data and spy_data.get("price") else "none"
                }
            except Exception as e:
                result["test_results"]["spy_market_data"] = {
                    "status": "error",
                    "error": str(e),
                    "duration_ms": round((time.time() - test_start) * 1000, 0)
                }
        else:
            result["connection"]["message"] = "è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥: 1) IB Gateway/TWS æ˜¯å¦è¿è¡Œ 2) ç«¯å£é…ç½®æ˜¯å¦æ­£ç¡® 3) API æ˜¯å¦å·²å¯ç”¨"
    
    except Exception as e:
        result["connection"]["status"] = "error"
        result["connection"]["message"] = f"è¯Šæ–­è¿‡ç¨‹å¼‚å¸¸: {str(e)}"
    
    return result

